{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_auc_score, roc_curve, accuracy_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Visualization style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Paths\n",
    "data_dir = Path(\"data/processed\")\n",
    "models_dir = Path(\"models\")\n",
    "models_dir.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02edec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed feature dataset (from feature_engineering.ipynb)\n",
    "X = pd.read_parquet(data_dir / \"X_features.parquet\")\n",
    "y = pd.read_parquet(data_dir / \"y_labels.parquet\")\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459b29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained models from feature_engineering.ipynb\n",
    "rf_model = joblib.load(models_dir / \"random_forest_model.joblib\")\n",
    "xgb_model = joblib.load(models_dir / \"xgboost_model.joblib\")\n",
    "dt_model = joblib.load(models_dir / \"decision_tree_model.joblib\")\n",
    "lr_model = joblib.load(models_dir / \"linear_regression_model.joblib\")\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"XGBoost\": xgb_model,\n",
    "    \"Decision Tree\": dt_model,\n",
    "    \"Linear Regression\": lr_model\n",
    "}\n",
    "\n",
    "print(\"Models loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba3e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models and store metrics\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X)\n",
    "    if hasattr(model, \"predict_proba\"):  # Tree-based models\n",
    "        y_prob = model.predict_proba(X)[:,1]\n",
    "    else:  # Linear Regression or models without predict_proba\n",
    "        y_prob = y_pred\n",
    "\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    auc = roc_auc_score(y, y_prob)\n",
    "    \n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(classification_report(y, y_pred, target_names=[\"Dismiss\", \"Report\"]))\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(f\"ROC AUC: {auc:.3f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=[\"Pred Dismiss\", \"Pred Report\"],\n",
    "                yticklabels=[\"True Dismiss\", \"True Report\"])\n",
    "    plt.title(f\"{name} Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y, y_prob)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"{name} ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"ROC_AUC\": auc\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cba425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize all model metrics\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"ROC_AUC\", ascending=False).reset_index(drop=True)\n",
    "print(\"Model Performance Summary:\")\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e444bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for Random Forest and XGBoost\n",
    "for name, model in [(\"Random Forest\", rf_model), (\"XGBoost\", xgb_model)]:\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        fi = pd.DataFrame({\n",
    "            \"Feature\": X.columns,\n",
    "            \"Importance\": model.feature_importances_\n",
    "        }).sort_values(by=\"Importance\", ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.barplot(x=\"Importance\", y=\"Feature\", data=fi)\n",
    "        plt.title(f\"{name} Feature Importance\")\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universal_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
